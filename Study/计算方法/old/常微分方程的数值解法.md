# 常微分方程的数值解法

最简单的常微分方程初值问题

$$
\left\{\begin{aligned}
& \dfrac{\mathrm{d} y}{\mathrm{~d} x}=f(x, y), x \in[a, b] \\
& y(a)=y_{0}
\end{aligned}\right.
$$

所谓数值解法, 就是求问题的解  $y(x)$  在一列点

$$
a=x_{0}<x_{1}<x_{2}<\cdots<x_{n}=b
$$

上值  $y\left(x_{i}\right)$  的近似值  $y_{i}(i=0,1,2, \cdots, n)$ . 相邻的两个结点之间的距离  $h_{i}=x_{i+1}-x_{i}$  称为由  $x_{i}$  到  $x_{i+1}$  的步长, 通常取成常量  $h$ .

**定义**

若  $y_{i+1}$  是在  $y_{j}=y\left(x_{j}\right)(j \leqslant i)$  的假定下, 由某数值方法得到的  $y\left(x_{i+1}\right)$  的近似值, 则称  $R_{i+1}=y\left(x_{i+1}\right)-y_{i+1}$  为该数值方法的**局部截断误差**.

如果一个数值方法的局部截断误差为  $O\left(h^{p+1}\right)$ , 则称这个方法的**阶数**为  $p$ , 或称它是一个  $p$  阶方法.

## 欧拉方法

**欧拉公式**(显式欧拉公式)

$$
y_{i+1}=y_{i}+h f\left(x_{i}, y_{i}\right) \quad(i=0,1, \cdots, n-1)
$$

可用于步进法求解常微分方程。

局部截断误差

$$
R_{i+1}=y\left(x_{i+1}\right)-y_{i+1}=\frac{h^{2}}{2} y^{\prime \prime}\left(x_{i}\right)+\frac{h^{3}}{6} y^{\prime \prime \prime}\left(\zeta_{i}\right)
$$

一阶方法

**后退的欧拉公式**(隐式欧拉公式)

$$
y_{i+1}=y_{i}+h f\left(x_{i+1}, y_{i+1}\right) \quad(i=0,1, \cdots, n-1)
$$

用迭代法求解

$$
y_{i+1}^{(k+1)}=y_{i}+h f\left(x_{i+1}, y_{i+1}^{(k)}\right) \quad(k=0,1,2, \cdots)
$$

局部截断误差

$$
R_{i+1}=-\frac{h^{2}}{2} y^{\prime \prime}\left(x_{i}\right)+O\left(h^{3}\right)
$$

一阶方法

**梯形公式**

$$
y_{i+1}=y_{i}+\frac{h}{2}\left[f\left(x_{i}, y_{i}\right)+\right. \left.f\left(x_{i+1}, y_{i+1}\right)\right] (i=0,1, \cdots, n-1)
$$

用迭代法求解

$$
\left\{\begin{aligned}
& y_{i+1}^{(0)}=y_{i}+h f\left(x_{i}, y_{i}\right), \\
& y_{i+1}^{(k+1)}=y_{i}+\frac{h}{2}\left[f\left(x_{i}, y_{i}\right)+f\left(x_{i+1}, y_{i+1}^{(k)}\right)\right] (k=0,1,2, \cdots)
\end{aligned}\right.
$$

二阶方法

**改进欧拉公式**

$$
\left\{\begin{aligned}
& \tilde{y}_{i+1}=y_{i}+h f\left(x_{i}, y_{i}\right), \\
& y_{i+1}=y_{i}+\frac{h}{2}\left[f\left(x_{i}, y_{i}\right)+f\left(x_{i+1}, \tilde{y}_{i+1}\right)\right] (i=0,1, \cdots, n-1)
\end{aligned}\right.
$$

二阶方法

## 龙格-库塔法 (R-K法)

微分中值定理

$$
y\left(x_{i+1}\right)=y\left(x_{i}\right)+h f(\zeta, y(\zeta)),\quad \zeta \in\left(x_{i}, x_{i+1}\right)
$$

龙格-库塔公式

$$
\left\{\begin{aligned}
& y_{i+1}=y_{i}+h\left(\alpha_{1} K_{1}+\alpha_{2} K_{2}+\cdots+\alpha_{m} K_{m}\right) \\
& K_{1}=f\left(x_{i}, y_{i}\right) \\
& K_{2}=f\left(x_{i}+\lambda_{2} h, y_{i}+\mu_{2} h\right) \\
& \cdots \cdots \cdots \cdots \\
& K_{m}=f\left(x_{i}+\lambda_{m} h, y_{i}+\mu_{m} h\right)
\end{aligned}\right.
$$

其中  $0 \leqslant \lambda_{j} \leqslant 1$, $y_{i}+\mu_{j} h$  是  $y\left(x_{i}+\lambda_{j} h\right)$  的预估值. 式中  $\alpha_{j}, \lambda_{j}, \mu_{j}$  都是待定参数.

### 二阶R-K法

$$
\left\{\begin{aligned}
& y_{i+1}=y_{i}+h\left(\alpha_{1} K_{1}+\alpha_{2} K_{2}\right) \\
& K_{1}=f\left(x_{i}, y_{i}\right) \\
& K_{2}=f\left(x_{i}+\lambda_{2} h, y_{i}+\lambda_{2} h K_{1}\right)
\end{aligned}\right.
$$

$$
\left\{\begin{aligned}
& \alpha_{1}+\alpha_{2}=1 \\
& \alpha_{2} \lambda_{2}=\frac{1}{2}
\end{aligned}\right.
$$

取

$$
\alpha_{1}=0, \alpha_{2}=1, \quad \lambda_{2}=\frac{1}{2}
$$

则得中点公式

$$
y_{i+1}=y_{i}+h f\left(x_{i}+\frac{1}{2} h, y_{i}+\frac{h}{2} f\left(x_{i}, y_{i}\right)\right),
$$

二阶R-K法都是二阶方法.


### 经典龙格-库塔法

$$
\left\{\begin{aligned}
& y_{i+1}=y_{i}+\frac{h}{6}\left(K_{1}+2 K_{2}+2 K_{3}+K_{4}\right) \\
& K_{1}=f\left(x_{i}, y_{i}\right) \\
& K_{2}=f\left(x_{i}+\frac{h}{2}, y_{i}+\frac{h}{2} K_{1}\right) \\
& K_{3}=f\left(x_{i}+\frac{h}{2}, y_{i}+\frac{h}{2} K_{2}\right) \\
& K_{4}=f\left(x_{i}+h, y_{i}+h K_{3}\right)
\end{aligned}\right.
$$

四阶方法


步长的自动选择 pass


## 收敛性与稳定性

**定义**

如果一个数值方法对任意固定的点  $x_{i}=x_{0}+i h$ , 当  $h=\frac{x_{i}-x_{0}}{i} \rightarrow 0$  (即  $i \rightarrow \infty$)  时都有  $y_{i} \rightarrow y\left(x_{i}\right)$ , 则称该法是**收敛**的.

数值方法的收敛性并不涉及计算过程中的舍人误差, 而只与方法的整体截断误差有关.

当  $y_{0}=y\left(x_{0}\right)$  时, 整体截断误差的阶数往往比局部截断误差低一阶.

**定义**

设用某一数值方法计算  $y_{i}$  时, 所得到的实际计算结果为  $\tilde{y}_{i}$ , 且由误差  $\delta_{i}=y_{i}-\tilde{y}_{i}$  引起以后各结点处  $y_{j}(j>i)$  的误差为  $\delta_{j}$ , 如果总有  $\left|\delta_{j}\right| \leqslant\left|\delta_{i}\right|$ , 则称该法是**绝对稳定**的.

为便于讨论, 常用试验方程

$$
y^{\prime}=\lambda y
$$

(其中  $\lambda$  为常数, 它可以是复数), 并且把能使某一数值方法绝对稳定的

$$
\tilde{h}=\lambda h
$$

的允许取值范围称为该法的**绝对稳定域**.

对于一般方程  $\dfrac{\mathrm{d} y}{\mathrm{~d} x}=f(x, y)$ , 可近似地取

$$
\lambda \approx-\left|\dfrac{\partial f}{\partial y}\right|_{\left(x_{i}, y_{i}\right)}
$$

以便判断绝对稳定性, 并用以确定求  $y_{i+1}$  时的步长  $h_{i+1}$ .

## 一阶方程组与高阶方程的数值解法

前几节研究了单个方程  $y^{\prime}=f(x, y)$  初值问题的数值解法. 若把  $y$  和  $f$  都理解为向量, 那么所提到过的各种方法, 都可推广应用到一阶方程组的情形.

$$
\left\{\begin{aligned}
& \boldsymbol{y}^{\prime}=f(x, \boldsymbol{y}), \\
& \boldsymbol{y}\left(x_{0}\right)=\boldsymbol{y}_{0},
& \end{aligned}\right.
$$

相应的经典 R-K公式

$$
\left\{\begin{aligned}
& \boldsymbol{y}_{i+1}=\boldsymbol{y}_{i}+\frac{h}{6}\left(K_{1}+2 K_{2}+2 K_{3}+K_{4}\right), \\
& K_{1}=f\left(x_{i}, \boldsymbol{y}_{i}\right), \\
& K_{2}=f\left(x_{i}+\frac{h}{2}, \boldsymbol{y}_{i}+\frac{h}{2} K_{1}\right), \\
& K_{3}=f\left(x_{i}+\frac{h}{2}, \boldsymbol{y}_{i}+\frac{h}{2} K_{2}\right), \\
& K_{4}=f\left(x_{i}+h, \boldsymbol{y}_{i}+h K_{3}\right) .
\end{aligned}\right.
$$

对于高阶常微分方程初值问题, 原则上总可以转化为一阶方程组求解.

## 边值问题的数值解法

二阶常微分方程

$$
y^{\prime \prime}=f\left(x, y, y^{\prime}\right), x \in[a, b]
$$

边值条件有

(1) 第一边值条件:  $y(a)=\alpha, y(b)=\beta$

(2) 第二边值条件:  $y^{\prime}(a)=\alpha, y^{\prime}(b)=\beta$

(3) 第三边值条件:  $y^{\prime}(a)-\omega_{1} y(a)=\alpha$, $y^{\prime}(b)+\omega_{2} y(b)=\beta$, 其中  $\omega_{1} \geqslant 0, \omega_{2} \geqslant 0, \omega_{1}+\omega_{2}>0$ .

### 打靶法

以第一边值问题为例

$$
\left\{\begin{array}{l}
y^{\prime \prime}=f\left(x, y, y^{\prime}\right), \\
y(a)=\alpha, y(b)=\beta
\end{array}\right.
$$

适当选取  $t$ , 构造初值问题

$$
\left\{\begin{array}{l}
y^{\prime \prime}=f\left(x, y, y^{\prime}\right), \\
y(a)=\alpha, y^{\prime}(a)=t,
\end{array}\right.
$$

$$
\beta_{1}=y\left(b, t_{1}\right), \beta_{2}=y\left(b, t_{2}\right) .
$$

若  $\left|\beta_{1}-\beta\right|<\varepsilon$  (或  $\left|\beta_{2}-\beta\right|<\varepsilon$  ), 则可取  $y\left(x, t_{1}\right)$  (或  $y\left(x, t_{2}\right)$  ) 作为边值问题的近似解; 否则当  $\beta_{1}$  与  $\beta_{2}$  互异时, 可用线性揷值方法 (或其他方法) 选取  $t$  的新预测值

$$
t_{3}=t_{1}+\frac{t_{2}-t_{1}}{\beta_{2}-\beta_{1}}\left(\beta-\beta_{1}\right)
$$

然后重新试算得  $\beta_{3} \cdots \cdots$  直到  $\left|\beta_{i}-\beta\right|<\varepsilon$  为止, 其中  $\beta_{i}=y\left(b, t_{i}\right)$ , 选取  $t_{i}$  的公式为

$$
t_{i}=t_{i-2}+\frac{t_{i-1}-t_{i-2}}{\beta_{i-1}-\beta_{i-2}}\left(\beta-\beta_{i-2}\right) \quad(i=3,4, \cdots) .
$$

